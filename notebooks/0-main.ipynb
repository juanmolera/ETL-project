{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd # data manipulation and dataframes\n",
    "import numpy as np # arrays manipulation and mathematical operations\n",
    "\n",
    "# Pandas configuration\n",
    "pd.set_option('display.max_columns', None)  # shows all columns\n",
    "pd.set_option('display.max_colwidth', None)  # shows all cell content\n",
    "\n",
    "# Fuzzy string matching\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Datetime\n",
    "from datetime import datetime\n",
    "\n",
    "# Pipeline connection\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import src.pipeline as pipe\n",
    "\n",
    "# Python SQL toolkit\n",
    "import sqlalchemy as alch\n",
    "\n",
    "# Secure password management system\n",
    "from getpass import getpass\n",
    "\n",
    "# Te quiero demasiado\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pipe.get_product_urls('https://www.dia.es/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL extraction with Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wanted information of each product\n",
    "scraping_result = {'supermarket': [],\n",
    "                'category': [],\n",
    "                'subcategory': [],\n",
    "                'name': [], \n",
    "                'price': [], \n",
    "                'reference_price': [],\n",
    "                'reference_unit': [],\n",
    "                'insert_date': []}\n",
    "\n",
    "\n",
    "scraping_result = pipe.scrap_products(scraping_result, urls)[0]\n",
    "total = pipe.scrap_products(scraping_result, urls)[1]\n",
    "\n",
    "# Export scraping result to csv\n",
    "df = pd.DataFrame(scraping_result)\n",
    "today_date = datetime.today().strftime('%Y-%m-%d %H-%M-%S')\n",
    "df.to_csv(f'../scrap({today_date}).csv', index = True, sep = ',')\n",
    "\n",
    "# Checks performance\n",
    "print(f'Scraped products: {len(scraping_result[\"name\"])} of {total}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads csvs\n",
    "initial_csv = pd.read_csv('../data/initial-dia.csv', index_col = 0)\n",
    "scraped_csv = pd.read_csv('../data/scraped-dia.csv', index_col = 0)\n",
    "\n",
    "# Index\n",
    "initial_csv.reset_index(drop = False, inplace = True) # resets index named by url\n",
    "\n",
    "# Nulls\n",
    "initial_csv.isnull().sum() # 3053473 description, 5480 reference_unit\n",
    "\n",
    "# Drops\n",
    "initial_csv.drop(columns=['description'], axis = 1, inplace = True) # descrition column (all values are null)\n",
    "initial_csv.drop(columns=['product_id'], axis = 1, inplace = True) # product_id column (not used information)\n",
    "#initial_csv.drop(columns=['url'], axis = 1, inplace = True) # url column (not used information)\n",
    "scraped_csv.drop(columns=['subcategory'], axis = 1, inplace = True) # subcategory column (not used information)\n",
    "\n",
    "# Gets YYYY-MM-DD format\n",
    "initial_csv['insert_date'] = initial_csv['insert_date'].str.split(' ', expand = True).get(0) \n",
    "\n",
    "# Matches reference_unit column content between both dfs\n",
    "units = scraped_csv['reference_unit'].tolist()\n",
    "\n",
    "new_units = []\n",
    "\n",
    "for u in units:\n",
    "\n",
    "    if u == 'kilo':\n",
    "        new_units.append('kg')\n",
    "\n",
    "    elif u == 'unidad':\n",
    "        new_units.append('ud')\n",
    "\n",
    "    elif u == 'litro':\n",
    "        new_units.append('l')\n",
    "\n",
    "    elif u == 'metro':\n",
    "        new_units.append('m')\n",
    "\n",
    "    elif u == 'lavado':\n",
    "        new_units.append('lavado')\n",
    "\n",
    "    else:\n",
    "        new_units.append(np.nan)\n",
    "\n",
    "scraped_csv['reference_unit'] = new_units\n",
    "\n",
    "# Adjusts column dtypes\n",
    "initial_csv['insert_date'] = pd.to_datetime(initial_csv['insert_date']) # to datetime\n",
    "scraped_csv['insert_date'] = pd.to_datetime(scraped_csv['insert_date']) # to datetime\n",
    "scraped_csv.iloc[2698, scraped_csv.columns.get_loc('reference_price')] = '13.82' # corrects supermarket labelling error\n",
    "scraped_csv['reference_price'] = pd.to_numeric(scraped_csv['reference_price']) # to float\n",
    "\n",
    "# No url info for scraped csv\n",
    "scraped_csv['url'] = '' # wip\n",
    "\n",
    "# Same column order\n",
    "scraped_csv = scraped_csv.reindex(columns = initial_csv.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching csvs by category with FuzzyWuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category column from both csvs to list\n",
    "new_categories = scraped_csv['category'].unique().tolist()\n",
    "old_categories = initial_csv['category'].unique().tolist()\n",
    "\n",
    "def best_match(col, new_categories_key_words):\n",
    "    '''\n",
    "    Finds most likely match between categories applying FuzzyWuzzy\n",
    "    Receives 2 arguments:\n",
    "        col (pd.Series): category column from initial csv\n",
    "        new_categories_key_words (list): list with category column key words from scraped csv\n",
    "    Returns 1 argument:\n",
    "        category (str): most likely match between categories after applying FuzzyWuzzy\n",
    "    '''\n",
    "    max_ratio = 0\n",
    "\n",
    "    for w in new_categories_key_words:\n",
    "\n",
    "        ratio = fuzz.ratio(col, w)\n",
    "\n",
    "        if ratio > max_ratio:\n",
    "\n",
    "            max_ratio = ratio\n",
    "            \n",
    "            category = w\n",
    "\n",
    "    return category\n",
    "\n",
    "# Splits scraped categories by '_'\n",
    "splitted_new = []\n",
    "\n",
    "for n in new_categories:\n",
    "\n",
    "    splitted_new.append(n.split('_'))\n",
    "\n",
    "# Flats splitted list\n",
    "flat = []\n",
    "\n",
    "for sublist in splitted_new:\n",
    "\n",
    "    for item in sublist:\n",
    "\n",
    "        flat.append(item)\n",
    "\n",
    "# Appends key words from new categories after discarting conjunctions\n",
    "new_categories_key_words = []\n",
    "\n",
    "for f in flat:\n",
    "\n",
    "    if f == 'y' or f == 'e' or f == 'con':\n",
    "\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "\n",
    "        new_categories_key_words.append(f)\n",
    "\n",
    "# Appends special categories as navidad and difficult terms to classify\n",
    "words_to_append = ['gluten', 'lacteos', 'navidad', 'dieteticos', 'solidario', 'aceitunas', 'sal', \n",
    "            'cuidado', 'internacional', 'mermeladas', 'licores', 'sopas', 'espumosos']\n",
    "\n",
    "for a in words_to_append:\n",
    "    \n",
    "    new_categories_key_words.append(a)\n",
    "\n",
    "# Splits initial categories by '_'\n",
    "splitted_old =[]\n",
    "\n",
    "for o in old_categories:\n",
    "\n",
    "    splitted_old.append(o.split('_'))\n",
    "\n",
    "\n",
    "# Discards difficult terms to classify\n",
    "old_categories_key_words = []\n",
    "words = ''\n",
    "\n",
    "words_to_discard = ['y', 'e', 'vinagre', 'con', 'del', 'al', 'de', 'dia', 'alimentacion', 'fresco', 'frescos', \n",
    "            'desayuno', 'despensa', 'bodega', 'drogueria', 'desayunos', 'dulces',\n",
    "            'cocina', 'personal', 'soy', 'bano', 'corporal', 'preparacion', 'bebidas']\n",
    "\n",
    "for sublist in splitted_old:\n",
    "\n",
    "    for item in sublist:\n",
    "        \n",
    "        if item in words_to_discard:\n",
    "\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "\n",
    "            words += item + ' '\n",
    "    \n",
    "    old_categories_key_words.append(words.rstrip(' '))\n",
    "\n",
    "    words = ''\n",
    "\n",
    "# Picks first key word from old categories\n",
    "old_first_key_word = []\n",
    "\n",
    "for w in old_categories_key_words:\n",
    "\n",
    "    old_first_key_word.append(w.split(' ')[0])\n",
    "\n",
    "# Generates a DataFrame with de most representative word from initial categories and the FuzzyWuzzy math result for the scraped categories\n",
    "df = pd.DataFrame()\n",
    "df['old_categories_key_words'] = pd.DataFrame(old_first_key_word)\n",
    "df['fuzzy_new_categories_key_words'] = df.apply(lambda x: best_match(x['old_categories_key_words'], new_categories_key_words), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After matching the categories by the most representative word it is neccesary to go back to original 'category names'\n",
    "\n",
    "# Appends key words from new categories after discarting conjunctions as before but in a list of lists (not in a flat list)\n",
    "key_words_list_new_categories = []\n",
    "aux = []\n",
    "\n",
    "for sublist in splitted_new:\n",
    "\n",
    "    for f in sublist:\n",
    "\n",
    "        if f == 'y' or f == 'e' or f == 'con':\n",
    "\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            \n",
    "            aux.append(f)\n",
    "            \n",
    "    key_words_list_new_categories.append(aux)\n",
    "    aux =[]\n",
    "\n",
    "def list_to_dict(words, category_key):\n",
    "    '''\n",
    "    Establish a relation between category name (key) and the list of the most representative words for that category (values)\n",
    "    Receives 2 arguments:\n",
    "        words (list): list of list of the most representative words for each category\n",
    "        category_key (str): category name from scraped csv\n",
    "    Returns 1 argument:\n",
    "        dict_category_key_words (dict): category name: list of representative words\n",
    "    '''\n",
    "    dict_category_key_words = {}\n",
    "    \n",
    "    for i, sublist in enumerate(words):\n",
    "\n",
    "        dict_category_key_words[category_key[i]] = sublist\n",
    "    \n",
    "    return dict_category_key_words\n",
    "\n",
    "# example {azucar_chocolates_y_caramelos}: [azucar, chocolates, caramelos]\n",
    "dict_category_key_words = list_to_dict(key_words_list_new_categories, new_categories)\n",
    "\n",
    "# Relates special categories as navidad and difficult terms to classify to the category names from the scraped csv (keys)\n",
    "\n",
    "# Special categories\n",
    "dict_category_key_words['gluten'] = ['gluten'] # sorry celiacos\n",
    "dict_category_key_words['solidario'] = ['solidario']\n",
    "dict_category_key_words['navidad'] = ['navidad']\n",
    "dict_category_key_words['internacional'] = ['internacional']\n",
    "\n",
    "# Difficult terms to classify\n",
    "dict_category_key_words['leche_huevos_y_mantequilla'].append('lacteos')\n",
    "dict_category_key_words['galletas_bollos_y_cereales'].append('dieteticos')\n",
    "dict_category_key_words['patatas_fritas_encurtidos_y_frutos_secos'].append('aceitunas')\n",
    "dict_category_key_words['aceites_salsas_y_especias'].append('sal')\n",
    "dict_category_key_words['perfumeria_higiene_salud'].append('cuidado')\n",
    "dict_category_key_words['azucar_chocolates_y_caramelos'].append('mermeladas')\n",
    "dict_category_key_words['cervezas_vinos_y_bebidas_con_alcohol'].append('licores')\n",
    "dict_category_key_words['conservas_caldos_y_cremas'].append('sopas')\n",
    "dict_category_key_words['cervezas_vinos_y_bebidas_con_alcohol'].append('espumosos')\n",
    "\n",
    "# Transforms most representative words used by FuzzyWuzzy to category names from the scraped csv\n",
    "# example leche: leche_huevos_y_mantequilla\n",
    "lst = []\n",
    "\n",
    "for i in df['fuzzy_new_categories_key_words']:\n",
    "\n",
    "    for key, values in dict_category_key_words.items():\n",
    "\n",
    "        if i in values:\n",
    "\n",
    "            lst.append(key) \n",
    "\n",
    "# Adds to DataFrame\n",
    "df['old_categories'] = old_categories\n",
    "df['new_categories'] = lst\n",
    "\n",
    "news = df['new_categories'].tolist()\n",
    "olds = df['old_categories'].unique().tolist()\n",
    "\n",
    "# Relates old categories (initial csv) to new categories (scraped csv)\n",
    "# {old}: new\n",
    "hada_dict = {}\n",
    "\n",
    "for i in range(0, len(news)):\n",
    "\n",
    "    hada_dict[olds[i]] = news[i]\n",
    "\n",
    "# Map\n",
    "initial_csv['new_categories'] = initial_csv['category'].map(hada_dict)\n",
    "\n",
    "# Drop old category column and rename\n",
    "initial_csv.drop(columns = ['category'], axis = 1, inplace = True)\n",
    "initial_csv.rename(columns = {'new_categories': 'category'}, inplace = True)\n",
    "\n",
    "# Same column order\n",
    "initial_csv = initial_csv.reindex(columns = scraped_csv.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_csv.to_csv('../eda/initial.csv', index = True, sep = ',')\n",
    "scraped_csv.to_csv('../eda/scraped.csv', index = True, sep = ',')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads csvs\n",
    "initial = pd.read_csv('../eda/initial.csv', index_col = 0)\n",
    "scraped = pd.read_csv('../eda/scraped.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores the password in a variable securely, so that nobody can see it\n",
    "password = getpass('Contraseña de MySQL: ')\n",
    "\n",
    "# Stores the name of our database in a variable\n",
    "db_name = 'supermarkets'\n",
    "\n",
    "# Creates the connection with MySQL\n",
    "connection = f'mysql+pymysql://root:{password}@localhost/{db_name}'\n",
    "\n",
    "# To connect to a database, we need to create a SQLAlchemy engine. The SQLAlchemy engine creates a common interface to the database for executing SQL statements.\n",
    "# It does this by wrapping a set of database connections and a dialect in such a way that they can work together to provide uniform access to the database.\n",
    "engine = alch.create_engine(connection)\n",
    "\n",
    "frames = [initial, scraped]\n",
    "concatenation = pd.concat(frames)\n",
    "concatenation.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data insertion into MySQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product table\n",
    "for index, row in tqdm(concatenation.iterrows()):\n",
    "\n",
    "    try: \n",
    "\n",
    "        engine.execute(f\"\"\"\n",
    "            INSERT INTO product (name, price, reference_price, reference_unit, date) VALUES\n",
    "            (\"{row[\"name\"]}\", \"{row[\"price\"]}\", \"{row[\"reference_price\"]}\", \"{row[\"reference_unit\"]}\", \"{row[\"insert_date\"]}\");\"\"\")\n",
    "    \n",
    "    except: \n",
    "\n",
    "        pass\n",
    "\n",
    "# Supermarket table\n",
    "for index, row in tqdm(concatenation.iterrows()):\n",
    "    \n",
    "    try: \n",
    "\n",
    "        engine.execute(f\"\"\"\n",
    "            INSERT INTO supermarket (name) VALUES\n",
    "            (\"{row[\"supermarket\"]}\");\"\"\")\n",
    "    \n",
    "    except: \n",
    "\n",
    "        pass\n",
    "\n",
    "# Category table\n",
    "for index, row in tqdm(concatenation.iterrows()):\n",
    "\n",
    "    try: \n",
    "\n",
    "        engine.execute(f\"\"\"\n",
    "            INSERT INTO category (name) VALUES\n",
    "            (\"{row[\"category\"]}\");\"\"\")\n",
    "    \n",
    "    except: \n",
    "\n",
    "        pass\n",
    "\n",
    "# URL table\n",
    "for index, row in tqdm(concatenation.iterrows()):\n",
    "\n",
    "    try: \n",
    "\n",
    "        engine.execute(f\"\"\"\n",
    "            INSERT INTO url (url) VALUES\n",
    "            (\"{row[\"url\"]}\");\"\"\")\n",
    "    \n",
    "    except: \n",
    "\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
