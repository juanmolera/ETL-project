{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejo de datos \n",
    "import pandas as pd # manejo de datos y dataframes\n",
    "import numpy as np # manejo de arrays y operaciones matematicas \n",
    "\n",
    "\n",
    "# Librerias para realizar web scraping con selenium\n",
    "from selenium import webdriver # webdriver permite manejar un navegador \n",
    "from webdriver_manager.chrome import ChromeDriverManager # permite instalar y mantener actualizado el driver de chrome\n",
    "from selenium.webdriver.common.keys import Keys # permite simular teclas del teclado \n",
    "from selenium.webdriver.chrome.options import Options # permite configurar el driver de chrome como modo incognito o maximizar la ventana\n",
    "from time import sleep # esperas entre ejecuciones de codigo\n",
    "\n",
    "\n",
    "import warnings # permite ignorar los warnings de python \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "opciones= Options()\n",
    "opciones.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "\n",
    "# para ocultarme como robot\n",
    "opciones.add_experimental_option('useAutomationExtension', False)\n",
    "opciones.add_argument('--start-maximized') # empezar maximizado\n",
    "opciones.add_argument('user.data-dir=selenium') # guarda las cookies\n",
    "opciones.add_argument('--incognito') # incognito window"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# para sacar solo ids y urls de los productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "flag = 0\n",
    "flag2 = 0\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.dia.es/\") \n",
    "sleep(3)\n",
    "\n",
    "# aceptamos las cookies \n",
    "driver.find_element(\"css selector\", '#onetrust-accept-btn-handler').click()\n",
    "sleep(2)\n",
    "\n",
    "# clicka productos\n",
    "driver.find_element(\"css selector\", '#app > div > div > div > div.home-view__header > div.dia-header > div.dia-header__section.dia-header__section--start > div > div > button').click()\n",
    "sleep(2)\n",
    "\n",
    "# para cada una de las categorías principales\n",
    "# poner un max excesivo\n",
    "for category in range(1,31):\n",
    "\n",
    "    while 1:\n",
    "\n",
    "        # intenta clickar\n",
    "        try:\n",
    "            \n",
    "            driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[1]/div[1]/div[1]/div/div[2]/div/div/div[2]/ul/li[{category}]/a').click()\n",
    "            flag2 = 0\n",
    "\n",
    "            for subcategory in range (1,31):\n",
    "\n",
    "                while 1:\n",
    "\n",
    "                    try:\n",
    "                        \n",
    "                        urls.append(driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[1]/div[1]/div[1]/div/div[2]/div/div/div[2]/ul/li[{category}]/ul/div[{subcategory}]/a').get_attribute(\"href\"))\n",
    "                        sleep(0.1)\n",
    "                        break\n",
    "\n",
    "                    except:\n",
    "\n",
    "                        flag2 = 1\n",
    "                        break\n",
    "                    \n",
    "                if flag2:\n",
    "                    break\n",
    "            \n",
    "            sleep(1)\n",
    "            break\n",
    "        \n",
    "        # break si se acaban\n",
    "        except:\n",
    "\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag:\n",
    "\n",
    "        break\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictio con los resultados del scrapeo\n",
    "resultados_dia = {'product_id': [],\n",
    "                'url': []}\n",
    "\n",
    "url = ['https://www.dia.es/charcuteria-y-quesos/jamon-cocido-lacon-fiambres-y-mortadela/c/L2001', \n",
    "       'https://www.dia.es/charcuteria-y-quesos/salchichas-y-elaborados/c/L2206']\n",
    "\n",
    "# creación del driver de chrome\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# para cada uno de los urls que han salido del primer Selenium\n",
    "for u in urls:\n",
    "\n",
    "        # get\n",
    "        driver.get(u)\n",
    "        sleep(3)\n",
    "\n",
    "        # acepta las cookies\n",
    "        try:\n",
    "                driver.find_element(\"css selector\", '#onetrust-accept-btn-handler').click()\n",
    "                sleep(0.2)\n",
    "\n",
    "        except:\n",
    "                pass\n",
    "\n",
    "        # scroll down\n",
    "        Y = 1200\n",
    "        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "        sleep(1)\n",
    "\n",
    "        # parsea html para sopa\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # listas resultados primera página\n",
    "        cat = soup.find(\"span\", {\"class\": \"plp-breadcrumb__first-level-category\"})\n",
    "        sub = soup.find(\"span\", {\"class\": \"plp-breadcrumb__second-level-category\"})\n",
    "        id = soup.find_all('div', attrs={'data-test-id': 'product-card'})\n",
    "        \n",
    "        # apendea los resultados de las listas al dictio extrayendo texto de labels y retocando con métodos de strings\n",
    "        \n",
    "        for i in id:\n",
    "\n",
    "                if re.findall('\\d{3,6}(?:P\\d+)?', str(i))[0]:\n",
    "                        resultados_dia['product_id'].append(re.findall('\\d{3,6}(?:P\\d+)?', str(i))[0])\n",
    "                        resultados_dia['url'].append('https://www.dia.es/'+cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"-\")+'/'+sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"-\")+'/p/'+re.findall('\\d{3,6}(?:P\\d+)?', str(i))[0])\n",
    "        \n",
    "                else:\n",
    "                        resultados_dia['product_id'].append(np.nan)\n",
    "                        resultados_dia['url'].append(np.nan)\n",
    "    \n",
    "        \n",
    "        # si hay botones, los encuentra\n",
    "        if bool(soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})):\n",
    "                botones = soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})\n",
    "\n",
    "        else:\n",
    "                pass\n",
    "        \n",
    "        # si hay botones (más páginas):\n",
    "        if botones:\n",
    "\n",
    "                # para cada botón siguiente (a partir del 2) hasta que se acaben:\n",
    "                for bottom in range(2, int(botones[-1].text)+1):\n",
    "\n",
    "                        # intenta clickar el botón\n",
    "                        try:\n",
    "                                driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div/div/div/div[{bottom}]/a').click()\n",
    "                                sleep(1)\n",
    "                        \n",
    "                        except:\n",
    "                                # para cuando hay botones flecha (+5 páginas)\n",
    "                                try:\n",
    "                                        driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div[1]/a[2]').click()\n",
    "                                        sleep(1)\n",
    "                                except:\n",
    "                                        pass\n",
    "\n",
    "                                pass\n",
    "                        \n",
    "                        # SE REPITE EL PROCESO ANTERIOR PARA EL RESTO DE PÁGINAS:\n",
    "                        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "                        sleep(1)\n",
    "\n",
    "                        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                        id = soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "\n",
    "                        for i in id:\n",
    "\n",
    "                                if re.findall('\\d{3,6}(?:P\\d+)?', str(i))[0]:\n",
    "                                        resultados_dia['product_id'].append(re.findall('\\d{3,6}(?:P\\d+)?', str(i))[0])\n",
    "                                        resultados_dia['url'].append('https://www.dia.es/'+cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"-\")+'/'+sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"-\")+'/p/'+re.findall('\\d{3,6}(?:P\\d+)?', str(i))[0])\n",
    "                        \n",
    "                                else:\n",
    "                                        resultados_dia['product_id'].append(np.nan)\n",
    "                                        resultados_dia['url'].append(np.nan)\n",
    "                        \n",
    "\n",
    "        # resetea nº botones\n",
    "        botones = []\n",
    "\n",
    "# cierra driver\n",
    "driver.quit()\n",
    "\n",
    "# show\n",
    "resultados_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(resultados_dia)\n",
    "\n",
    "df.to_csv(\"../a.csv\", index=False, sep= \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resultados_dia['product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resultados_dia['url'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
