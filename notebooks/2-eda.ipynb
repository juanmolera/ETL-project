{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd # data manipulation and dataframes\n",
    "import numpy as np # arrays manipulation and mathematical operations\n",
    "\n",
    "# Fuzzy string matching\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas configuration\n",
    "pd.set_option('display.max_columns', None)  # shows all columns\n",
    "pd.set_option('display.max_colwidth', None)  # shows all cell content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads csvs\n",
    "initial_csv = pd.read_csv('../data/initial-dia.csv', index_col = 0)\n",
    "scrapped_csv = pd.read_csv('../data/scraped-dia.csv', index_col = 0)\n",
    "\n",
    "# Index\n",
    "initial_csv.reset_index(drop = False, inplace = True) # resets index named by url\n",
    "\n",
    "# Nulls\n",
    "initial_csv.isnull().sum() # 3053473 description, 5480 reference_unit\n",
    "\n",
    "# Drops\n",
    "initial_csv.drop(columns=['description'], axis = 1, inplace = True) # descrition column (all values are null)\n",
    "initial_csv.drop(columns=['product_id'], axis = 1, inplace = True) # product_id column (not used information)\n",
    "scrapped_csv.drop(columns=['subcategory'], axis = 1, inplace = True) # subcategory column (not used information)\n",
    "\n",
    "# Gets YYYY-MM-DD format\n",
    "initial_csv['insert_date'] = initial_csv['insert_date'].str.split(' ', expand = True).get(0) \n",
    "\n",
    "# Matches reference_unit column content between both dfs\n",
    "units = scrapped_csv['reference_unit'].tolist()\n",
    "\n",
    "new_units = []\n",
    "\n",
    "for u in units:\n",
    "\n",
    "    if u == 'kilo':\n",
    "        new_units.append('kg')\n",
    "\n",
    "    elif u == 'unidad':\n",
    "        new_units.append('ud')\n",
    "\n",
    "    elif u == 'litro':\n",
    "        new_units.append('l')\n",
    "\n",
    "    elif u == 'metro':\n",
    "        new_units.append('m')\n",
    "\n",
    "    elif u == 'lavado':\n",
    "        new_units.append('lavado')\n",
    "\n",
    "    else:\n",
    "        new_units.append(np.nan)\n",
    "\n",
    "scrapped_csv['reference_unit'] = new_units\n",
    "\n",
    "# Adjusts column dtypes\n",
    "initial_csv['insert_date'] = pd.to_datetime(initial_csv['insert_date']) # to datetime\n",
    "scrapped_csv['insert_date'] = pd.to_datetime(scrapped_csv['insert_date']) # to datetime\n",
    "scrapped_csv.iloc[2698, scrapped_csv.columns.get_loc('reference_price')] = '13.82' # corrects supermarket labelling error\n",
    "scrapped_csv['reference_price'] = pd.to_numeric(scrapped_csv['reference_price']) # to float\n",
    "\n",
    "# No url info for scraped csv\n",
    "scrapped_csv['url'] = np.nan # wip\n",
    "\n",
    "# Same column order\n",
    "scrapped_csv = scrapped_csv.reindex(columns = initial_csv.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching csvs by category with FuzzyWuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paso a listas las cols de categoría del dataframe scrapeado y del inicial\n",
    "cat_nuevas = scrapped_csv['category'].unique().tolist()\n",
    "cat_antiguas = initial_csv['category'].unique().tolist()\n",
    "\n",
    "def cat_max(col, limpita):\n",
    "    '''\n",
    "    Devuelve categoría tras aplicar fuzzywuzzy\n",
    "    '''\n",
    "\n",
    "    maximo = 0\n",
    "\n",
    "    for l in limpita:\n",
    "\n",
    "        parecido = fuzz.ratio(col, l)\n",
    "\n",
    "        if parecido > maximo:\n",
    "\n",
    "            maximo = parecido\n",
    "            \n",
    "            categoria = l\n",
    "\n",
    "    return categoria\n",
    "\n",
    "# splitea los valores de las categorías scrapeadas por '_'\n",
    "spliteada = []\n",
    "\n",
    "for s in cat_nuevas:\n",
    "\n",
    "    a = s.split('_')\n",
    "\n",
    "    spliteada.append(a)\n",
    "\n",
    "# flatea la lista para pasar de lista de listas a lista de strs\n",
    "flat_list = []\n",
    "\n",
    "for sublist in spliteada:\n",
    "\n",
    "    for item in sublist:\n",
    "\n",
    "        flat_list.append(item)\n",
    "\n",
    "# apendea en una lista todas las palabras eliminando aquellas de poco interés para el fuzzywuzzy\n",
    "limpita = []\n",
    "\n",
    "for f in flat_list:\n",
    "\n",
    "    # se evitan los nexos entre palabras\n",
    "    if f == 'y' or f == 'e' or f == 'con':\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        limpita.append(f)\n",
    "\n",
    "\n",
    "# añade a lo lista limpia anterior algunas categorías especiales como navidad y otros términos complicados de clasificar\n",
    "apendeos = ['gluten', 'lacteos', 'navidad', 'dieteticos', 'solidario', 'aceitunas', 'sal', \n",
    "            'cuidado', 'internacional', 'mermeladas', 'licores', 'sopas', 'espumosos']\n",
    "\n",
    "for a in apendeos:\n",
    "    \n",
    "    limpita.append(a)\n",
    "\n",
    "# splitea los valores de las categorías iniciales por '_'\n",
    "aux =[]\n",
    "\n",
    "for c in cat_antiguas:\n",
    "\n",
    "    aux.append(c.split('_'))\n",
    "\n",
    "\n",
    "# descarta palabras que dificultan el matcheo por fuzzywuzzy\n",
    "aux2 = []\n",
    "word = ''\n",
    "\n",
    "descartes = ['y', 'e', 'vinagre', 'con', 'del', 'al', 'de', 'dia', 'alimentacion', 'fresco', 'frescos', \n",
    "            'desayuno', 'despensa', 'bodega', 'drogueria', 'desayunos', 'dulces',\n",
    "            'cocina', 'personal', 'soy', 'bano', 'corporal', 'preparacion', 'bebidas']\n",
    "\n",
    "for a in aux:\n",
    "\n",
    "    for i in a:\n",
    "        \n",
    "        if i in descartes:\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            word += i + ' '\n",
    "    \n",
    "    aux2.append(word.rstrip(' '))\n",
    "\n",
    "    word = ''\n",
    "\n",
    "# para cada una de las listas de strs de categorías iniciales tras los descartes se selecciona solo la primera palabra, la más representativa\n",
    "aux3 = []\n",
    "\n",
    "for a in aux2:\n",
    "\n",
    "    b = a.split(' ')\n",
    "    aux3.append(b[0])\n",
    "\n",
    "# genera un df con la palabra representativa de las categorías iniciales y con las resultantes del fuzzywuzzy\n",
    "df = pd.DataFrame()\n",
    "df['antiguas'] = pd.DataFrame(aux3)\n",
    "df['fuzzcat'] = df.apply(lambda x: cat_max(x['antiguas'], limpita), axis = 1)\n",
    "\n",
    "# YA SE HAN RELACIONADO LAS CATEGORÍAS CON FUZZYWUZZY\n",
    "# AHORA HAY QUE HACER EL PROCESO CONTRARIO DE RELACIONAR LAS PALABRAS CLAVES MATCHEADAS CON LOS NOMBRES DE LAS CATEGORÍAS\n",
    "\n",
    "# se repite el proceso de descartar nexos entre palabras para las categorías scrapeadas, pero se mantiene la estructura de lista de listas y no se flatea como anteriormente\n",
    "definitiva = []\n",
    "aux = []\n",
    "for sublist in spliteada:\n",
    "\n",
    "    for f in sublist:\n",
    "\n",
    "        if f == 'y' or f == 'e' or f == 'con':\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            aux.append(f)\n",
    "    definitiva.append(aux)\n",
    "    aux =[]\n",
    "\n",
    "\n",
    "def convertir_lista_a_diccionario(lista, claves):\n",
    "    '''\n",
    "    Convierte una lista de listas en un diccionario según unas keys dadas\n",
    "    '''\n",
    "    dictio = {}\n",
    "    \n",
    "    for i, sublist in enumerate(lista):\n",
    "\n",
    "        clave = claves[i]\n",
    "        dictio[clave] = sublist\n",
    "    \n",
    "    return dictio\n",
    "\n",
    "# crea un diccionario {categorias scrapeadas}: [palabras clave de la categoría usadas para fuzzywuzzy]\n",
    "# ejemplo {azucar_chocolates_y_caramelos}: [azucar, chocolates, caramelos]\n",
    "lista_de_listas = definitiva\n",
    "dictio = convertir_lista_a_diccionario(lista_de_listas, cat_nuevas)\n",
    "\n",
    "# relaciona los apendeos con categorías existentes o crea nuevas categorías\n",
    "# nuevas categorías:\n",
    "dictio['gluten'] = ['gluten'] # sorry celiacos\n",
    "dictio['solidario'] = ['solidario']\n",
    "dictio['navidad'] = ['navidad']\n",
    "dictio['internacional'] = ['internacional']\n",
    "\n",
    "# relaciona términos con categorías existentes:\n",
    "dictio['leche_huevos_y_mantequilla'].append('lacteos')\n",
    "dictio['galletas_bollos_y_cereales'].append('dieteticos')\n",
    "dictio['patatas_fritas_encurtidos_y_frutos_secos'].append('aceitunas')\n",
    "dictio['aceites_salsas_y_especias'].append('sal')\n",
    "dictio['perfumeria_higiene_salud'].append('cuidado')\n",
    "dictio['azucar_chocolates_y_caramelos'].append('mermeladas')\n",
    "dictio['cervezas_vinos_y_bebidas_con_alcohol'].append('licores')\n",
    "dictio['conservas_caldos_y_cremas'].append('sopas')\n",
    "dictio['cervezas_vinos_y_bebidas_con_alcohol'].append('espumosos')\n",
    "\n",
    "# transforma las palabras clave de fuzzywuzzy en las categorías scrapeadas categorías scrapeadas\n",
    "# ejemplo leche: leche_huevos_y_mantequilla\n",
    "listiña = []\n",
    "\n",
    "for i in df['fuzzcat']:\n",
    "\n",
    "    for key, values in dictio.items():\n",
    "\n",
    "        if i in values:\n",
    "\n",
    "            listiña.append(key)\n",
    "\n",
    "# añade al df\n",
    "df['feas'] = cat_antiguas\n",
    "df['transformadas'] = listiña\n",
    "\n",
    "transformadas = df['transformadas'].tolist()\n",
    "feas = df['feas'].unique().tolist()\n",
    "\n",
    "# diccionario para transformas las categorías iniciales en las categorías scrapeadas\n",
    "# {categoría inicial}: categoría scrapeada\n",
    "hada = {}\n",
    "\n",
    "for i in range(0, len(transformadas)):\n",
    "\n",
    "    hada[feas[i]] = transformadas[i]\n",
    "\n",
    "# map\n",
    "initial_csv['nuevas_categorias'] = initial_csv['category'].map(hada)\n",
    "\n",
    "# drop old and rename\n",
    "initial_csv.drop(columns=['category'], axis = 1, inplace = True)\n",
    "initial_csv.rename(columns={\"nuevas_categorias\": \"category\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
