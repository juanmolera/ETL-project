{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd # data manipulation and dataframes\n",
    "import numpy as np # arrays manipulation and mathematical operations\n",
    "\n",
    "# Fuzzy string matching\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas configuration\n",
    "pd.set_option('display.max_columns', None)  # shows all columns\n",
    "pd.set_option('display.max_colwidth', None)  # shows all cell content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads csvs\n",
    "initial_csv = pd.read_csv('../data/initial-dia.csv', index_col = 0)\n",
    "scrapped_csv = pd.read_csv('../data/scraped-dia.csv', index_col = 0)\n",
    "\n",
    "# Index\n",
    "initial_csv.reset_index(drop = False, inplace = True) # resets index named by url\n",
    "\n",
    "# Nulls\n",
    "initial_csv.isnull().sum() # 3053473 description, 5480 reference_unit\n",
    "\n",
    "# Drops\n",
    "initial_csv.drop(columns=['description'], axis = 1, inplace = True) # descrition column (all values are null)\n",
    "initial_csv.drop(columns=['product_id'], axis = 1, inplace = True) # product_id column (not used information)\n",
    "#initial_csv.drop(columns=['url'], axis = 1, inplace = True) # url column (not used information)\n",
    "scrapped_csv.drop(columns=['subcategory'], axis = 1, inplace = True) # subcategory column (not used information)\n",
    "\n",
    "# Gets YYYY-MM-DD format\n",
    "initial_csv['insert_date'] = initial_csv['insert_date'].str.split(' ', expand = True).get(0) \n",
    "\n",
    "# Matches reference_unit column content between both dfs\n",
    "units = scrapped_csv['reference_unit'].tolist()\n",
    "\n",
    "new_units = []\n",
    "\n",
    "for u in units:\n",
    "\n",
    "    if u == 'kilo':\n",
    "        new_units.append('kg')\n",
    "\n",
    "    elif u == 'unidad':\n",
    "        new_units.append('ud')\n",
    "\n",
    "    elif u == 'litro':\n",
    "        new_units.append('l')\n",
    "\n",
    "    elif u == 'metro':\n",
    "        new_units.append('m')\n",
    "\n",
    "    elif u == 'lavado':\n",
    "        new_units.append('lavado')\n",
    "\n",
    "    else:\n",
    "        new_units.append(np.nan)\n",
    "\n",
    "scrapped_csv['reference_unit'] = new_units\n",
    "\n",
    "# Adjusts column dtypes\n",
    "initial_csv['insert_date'] = pd.to_datetime(initial_csv['insert_date']) # to datetime\n",
    "scrapped_csv['insert_date'] = pd.to_datetime(scrapped_csv['insert_date']) # to datetime\n",
    "scrapped_csv.iloc[2698, scrapped_csv.columns.get_loc('reference_price')] = '13.82' # corrects supermarket labelling error\n",
    "scrapped_csv['reference_price'] = pd.to_numeric(scrapped_csv['reference_price']) # to float\n",
    "\n",
    "# No url info for scraped csv\n",
    "scrapped_csv['url'] = '' # wip\n",
    "\n",
    "# Same column order\n",
    "scrapped_csv = scrapped_csv.reindex(columns = initial_csv.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching csvs by category with FuzzyWuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category column from both csvs to list\n",
    "new_categories = scrapped_csv['category'].unique().tolist()\n",
    "old_categories = initial_csv['category'].unique().tolist()\n",
    "\n",
    "def best_match(col, new_categories_key_words):\n",
    "    '''\n",
    "    Finds most likely match between categories after applying FuzzyWuzzy\n",
    "    Receives 2 arguments:\n",
    "        col (pd.Series): category column from initial csv\n",
    "        new_categories_key_words (list): list with category column key words from scraped csv\n",
    "    Returns 1 argument:\n",
    "        category (str): most likely match between categories after applying FuzzyWuzzy\n",
    "    '''\n",
    "    max_ratio = 0\n",
    "\n",
    "    for w in new_categories_key_words:\n",
    "\n",
    "        ratio = fuzz.ratio(col, w)\n",
    "\n",
    "        if ratio > max_ratio:\n",
    "\n",
    "            max_ratio = ratio\n",
    "            \n",
    "            category = w\n",
    "\n",
    "    return category\n",
    "\n",
    "# Splits scraped categories by '_'\n",
    "splitted_new = []\n",
    "\n",
    "for n in new_categories:\n",
    "\n",
    "    splitted_new.append(n.split('_'))\n",
    "\n",
    "# Flats splitted list\n",
    "flat = []\n",
    "\n",
    "for sublist in splitted_new:\n",
    "\n",
    "    for item in sublist:\n",
    "\n",
    "        flat.append(item)\n",
    "\n",
    "# Appends key words from new categories after discarting conjunctions\n",
    "new_categories_key_words = []\n",
    "\n",
    "for f in flat:\n",
    "\n",
    "    if f == 'y' or f == 'e' or f == 'con':\n",
    "\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "\n",
    "        new_categories_key_words.append(f)\n",
    "\n",
    "# Appends special categories as navidad and difficult terms to classify\n",
    "words_to_append = ['gluten', 'lacteos', 'navidad', 'dieteticos', 'solidario', 'aceitunas', 'sal', \n",
    "            'cuidado', 'internacional', 'mermeladas', 'licores', 'sopas', 'espumosos']\n",
    "\n",
    "for a in words_to_append:\n",
    "    \n",
    "    new_categories_key_words.append(a)\n",
    "\n",
    "# Splits initial categories by '_'\n",
    "splitted_old =[]\n",
    "\n",
    "for o in old_categories:\n",
    "\n",
    "    splitted_old.append(o.split('_'))\n",
    "\n",
    "\n",
    "# Discards difficult terms to classify\n",
    "old_categories_key_words = []\n",
    "words = ''\n",
    "\n",
    "words_to_discard = ['y', 'e', 'vinagre', 'con', 'del', 'al', 'de', 'dia', 'alimentacion', 'fresco', 'frescos', \n",
    "            'desayuno', 'despensa', 'bodega', 'drogueria', 'desayunos', 'dulces',\n",
    "            'cocina', 'personal', 'soy', 'bano', 'corporal', 'preparacion', 'bebidas']\n",
    "\n",
    "for sublist in splitted_old:\n",
    "\n",
    "    for item in sublist:\n",
    "        \n",
    "        if item in words_to_discard:\n",
    "\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "\n",
    "            words += item + ' '\n",
    "    \n",
    "    old_categories_key_words.append(words.rstrip(' '))\n",
    "\n",
    "    words = ''\n",
    "\n",
    "# Picks first key word from old categories\n",
    "old_first_key_word = []\n",
    "\n",
    "for w in old_categories_key_words:\n",
    "\n",
    "    old_first_key_word.append(w.split(' ')[0])\n",
    "\n",
    "# Generates a DataFrame with de most representative word from initial categories and the FuzzyWuzzy math result for the scraped categories\n",
    "df = pd.DataFrame()\n",
    "df['old_categories_key_words'] = pd.DataFrame(old_first_key_word)\n",
    "df['fuzzy_new_categories_key_words'] = df.apply(lambda x: best_match(x['old_categories_key_words'], new_categories_key_words), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After matching the categories by the most representative word it is neccesary to go back to original 'category names'\n",
    "\n",
    "# Appends key words from new categories after discarting conjunctions as before but in a list of lists (not in a flat list)\n",
    "key_words_list_new_categories = []\n",
    "aux = []\n",
    "\n",
    "for sublist in splitted_new:\n",
    "\n",
    "    for f in sublist:\n",
    "\n",
    "        if f == 'y' or f == 'e' or f == 'con':\n",
    "\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            \n",
    "            aux.append(f)\n",
    "            \n",
    "    key_words_list_new_categories.append(aux)\n",
    "    aux =[]\n",
    "\n",
    "def list_to_dict(words, category_key):\n",
    "    '''\n",
    "    Establish a relation between category name (key) and the list of the most representative words for that category (values)\n",
    "    Receives 2 arguments:\n",
    "        words (list): list of list of the most representative words for each category\n",
    "        category_key (str): category name from scrapped csv\n",
    "    Returns 1 argument:\n",
    "        dict_category_key_words (dict): category name: list of representative words\n",
    "    '''\n",
    "    dict_category_key_words = {}\n",
    "    \n",
    "    for i, sublist in enumerate(words):\n",
    "\n",
    "        dict_category_key_words[category_key[i]] = sublist\n",
    "    \n",
    "    return dict_category_key_words\n",
    "\n",
    "# example {azucar_chocolates_y_caramelos}: [azucar, chocolates, caramelos]\n",
    "dict_category_key_words = list_to_dict(key_words_list_new_categories, new_categories)\n",
    "\n",
    "# Relates special categories as navidad and difficult terms to classify to the category names from the scraped csv (keys)\n",
    "\n",
    "# Special categories\n",
    "dict_category_key_words['gluten'] = ['gluten'] # sorry celiacos\n",
    "dict_category_key_words['solidario'] = ['solidario']\n",
    "dict_category_key_words['navidad'] = ['navidad']\n",
    "dict_category_key_words['internacional'] = ['internacional']\n",
    "\n",
    "# Difficult terms to classify\n",
    "dict_category_key_words['leche_huevos_y_mantequilla'].append('lacteos')\n",
    "dict_category_key_words['galletas_bollos_y_cereales'].append('dieteticos')\n",
    "dict_category_key_words['patatas_fritas_encurtidos_y_frutos_secos'].append('aceitunas')\n",
    "dict_category_key_words['aceites_salsas_y_especias'].append('sal')\n",
    "dict_category_key_words['perfumeria_higiene_salud'].append('cuidado')\n",
    "dict_category_key_words['azucar_chocolates_y_caramelos'].append('mermeladas')\n",
    "dict_category_key_words['cervezas_vinos_y_bebidas_con_alcohol'].append('licores')\n",
    "dict_category_key_words['conservas_caldos_y_cremas'].append('sopas')\n",
    "dict_category_key_words['cervezas_vinos_y_bebidas_con_alcohol'].append('espumosos')\n",
    "\n",
    "# Transforms most representative words used by FuzzyWuzzy to category names from the scraped csv\n",
    "# example leche: leche_huevos_y_mantequilla\n",
    "lst = []\n",
    "\n",
    "for i in df['fuzzy_new_categories_key_words']:\n",
    "\n",
    "    for key, values in dict_category_key_words.items():\n",
    "\n",
    "        if i in values:\n",
    "\n",
    "            lst.append(key) \n",
    "\n",
    "# Adds to DataFrame\n",
    "df['old_categories'] = old_categories\n",
    "df['new_categories'] = lst\n",
    "\n",
    "news = df['new_categories'].tolist()\n",
    "olds = df['old_categories'].unique().tolist()\n",
    "\n",
    "# Relates old categories (initial csv) to new categories (scraped csv)\n",
    "# {old}: new\n",
    "hada_dict = {}\n",
    "\n",
    "for i in range(0, len(news)):\n",
    "\n",
    "    hada_dict[olds[i]] = news[i]\n",
    "\n",
    "# Map\n",
    "initial_csv['new_categories'] = initial_csv['category'].map(hada_dict)\n",
    "\n",
    "# Drop old category column and rename\n",
    "initial_csv.drop(columns=['category'], axis = 1, inplace = True)\n",
    "initial_csv.rename(columns={\"new_categories\": \"category\"}, inplace=True)\n",
    "\n",
    "# Same column order\n",
    "initial_csv = initial_csv.reindex(columns = scrapped_csv.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
