{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejo de datos \n",
    "import pandas as pd # manejo de datos y dataframes\n",
    "import numpy as np # manejo de arrays y operaciones matematicas \n",
    "\n",
    "\n",
    "# Librerias para realizar web scraping con selenium\n",
    "from selenium import webdriver # webdriver permite manejar un navegador \n",
    "from webdriver_manager.chrome import ChromeDriverManager # permite instalar y mantener actualizado el driver de chrome\n",
    "from selenium.webdriver.common.keys import Keys # permite simular teclas del teclado \n",
    "from selenium.webdriver.chrome.options import Options # permite configurar el driver de chrome como modo incognito o maximizar la ventana\n",
    "from time import sleep # esperas entre ejecuciones de codigo\n",
    "\n",
    "\n",
    "import warnings # permite ignorar los warnings de python \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "opciones= Options()\n",
    "opciones.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "\n",
    "# para ocultarme como robot\n",
    "opciones.add_experimental_option('useAutomationExtension', False)\n",
    "opciones.add_argument('--start-maximized') # empezar maximizado\n",
    "opciones.add_argument('user.data-dir=selenium') # guarda las cookies\n",
    "opciones.add_argument('--incognito') # incognito window"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracción de urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "flag = 0\n",
    "flag2 = 0\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.dia.es/\") \n",
    "sleep(3)\n",
    "\n",
    "# aceptamos las cookies \n",
    "driver.find_element(\"css selector\", '#onetrust-accept-btn-handler').click()\n",
    "sleep(2)\n",
    "\n",
    "# clicka productos\n",
    "driver.find_element(\"css selector\", '#app > div > div > div > div.home-view__header > div.dia-header > div.dia-header__section.dia-header__section--start > div > div > button').click()\n",
    "sleep(2)\n",
    "\n",
    "# para cada una de las categorías principales\n",
    "# poner un max excesivo\n",
    "for category in range(1,31):\n",
    "\n",
    "    while 1:\n",
    "\n",
    "        # intenta clickar\n",
    "        try:\n",
    "            \n",
    "            driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[1]/div[1]/div[1]/div/div[2]/div/div/div[2]/ul/li[{category}]/a').click()\n",
    "            flag2 = 0\n",
    "\n",
    "            for subcategory in range (1,31):\n",
    "\n",
    "                while 1:\n",
    "\n",
    "                    try:\n",
    "                        \n",
    "                        urls.append(driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[1]/div[1]/div[1]/div/div[2]/div/div/div[2]/ul/li[{category}]/ul/div[{subcategory}]/a').get_attribute(\"href\"))\n",
    "                        sleep(0.1)\n",
    "                        break\n",
    "\n",
    "                    except:\n",
    "\n",
    "                        flag2 = 1\n",
    "                        break\n",
    "                    \n",
    "                if flag2:\n",
    "                    break\n",
    "            \n",
    "            sleep(1)\n",
    "            break\n",
    "        \n",
    "        # break si se acaban\n",
    "        except:\n",
    "\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag:\n",
    "\n",
    "        break\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrapeo de productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_dia = {'supermarket': [],\n",
    "                'category': [],\n",
    "                'subcategory': [],\n",
    "                'name': [], \n",
    "                'price': [], \n",
    "                'reference_price': [],\n",
    "                'reference_unit': [],\n",
    "                'insert_date': []}\n",
    "\n",
    "total = 0\n",
    "botones = []\n",
    "\n",
    "# creación del driver de chrome\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# para cada uno de los urls que han salido del primer Selenium\n",
    "for u in urls:\n",
    "\n",
    "        # get\n",
    "        driver.get(u)\n",
    "        sleep(3)\n",
    "\n",
    "        # acepta las cookies\n",
    "        try:\n",
    "                driver.find_element(\"css selector\", '#onetrust-accept-btn-handler').click()\n",
    "                sleep(1)\n",
    "\n",
    "        except:\n",
    "                pass\n",
    "\n",
    "        # scroll down\n",
    "        Y = 1200\n",
    "        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "        sleep(1)\n",
    "\n",
    "        # parsea html para sopa\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # listas resultados primera página\n",
    "        cat = soup.find(\"span\", {\"class\": \"plp-breadcrumb__first-level-category\"})\n",
    "        sub = soup.find(\"span\", {\"class\": \"plp-breadcrumb__second-level-category\"})\n",
    "        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "\n",
    "        # cálculo del nº total de productos existentes en el super\n",
    "        try:\n",
    "                num = soup.find('span', {\"class\": \"plp-breadcrumb__total-items\"}).text\n",
    "\n",
    "        except:\n",
    "                num = 0\n",
    "\n",
    "        total += int(re.findall('\\d+', str(num))[0])\n",
    "        \n",
    "        # apendea los resultados de las listas al dictio extrayendo texto de labels y retocando con métodos de strings\n",
    "        for p in prod:\n",
    "                resultados_dia['supermarket'].append('dia-es')\n",
    "                resultados_dia['category'].append(cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace('ñ', 'n').replace(',', '').replace(\" \", \"_\"))\n",
    "                resultados_dia['subcategory'].append(sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace('ñ', 'n').replace(',', '').replace(\" \", \"_\"))\n",
    "                resultados_dia['name'].append(p.text)\n",
    "                resultados_dia['insert_date'].append(datetime.today().strftime('%Y-%m-%d'))\n",
    "                        \n",
    "        for o in precio:\n",
    "                resultados_dia['price'].append(o.text.rstrip('\\xa0€').replace(',', '.'))\n",
    "        \n",
    "        for k in kilo:\n",
    "                lst = k.text.split('\\xa0€/')\n",
    "                resultados_dia['reference_price'].append(lst[0].lstrip(' (').replace(',', '.'))\n",
    "                resultados_dia['reference_unit'].append(lst[1].rstrip(') ').lower())\n",
    "        \n",
    "        # si hay botones, los encuentra\n",
    "        if bool(soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})):\n",
    "                botones = soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})\n",
    "\n",
    "        else:\n",
    "                pass\n",
    "        \n",
    "        # si hay botones (más páginas):\n",
    "        if botones:\n",
    "\n",
    "                # para cada botón siguiente (a partir del 2) hasta que se acaben:\n",
    "                for bottom in range(2, int(botones[-1].text)+1):\n",
    "\n",
    "                        # intenta clickar el botón\n",
    "                        try:\n",
    "                                driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div/div/div/div[{bottom}]/a').click()\n",
    "                                sleep(1)\n",
    "                        \n",
    "                        except:\n",
    "                                # para cuando hay botones flecha (+5 páginas)\n",
    "                                try:\n",
    "                                        driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div[1]/a[2]').click()\n",
    "                                        sleep(1)\n",
    "                                except:\n",
    "                                        pass\n",
    "\n",
    "                                pass\n",
    "                        \n",
    "                        # SE REPITE EL PROCESO ANTERIOR PARA EL RESTO DE PÁGINAS:\n",
    "                        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "                        sleep(1)\n",
    "\n",
    "                        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "                        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "                        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "                        \n",
    "                        for p in prod:\n",
    "                                resultados_dia['supermarket'].append('dia-es')\n",
    "                                resultados_dia['category'].append(cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace('ñ', 'n').replace(',', '').replace(\" \", \"_\"))\n",
    "                                resultados_dia['subcategory'].append(sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace('ñ', 'n').replace(',', '').replace(\" \", \"_\"))\n",
    "                                resultados_dia['name'].append(p.text)\n",
    "                                resultados_dia['insert_date'].append(datetime.today().strftime('%Y-%m-%d'))\n",
    "\n",
    "                        for o in precio:\n",
    "                                resultados_dia['price'].append(o.text.rstrip('\\xa0€').replace(',', '.'))\n",
    "                        \n",
    "                        for k in kilo:\n",
    "                                lst = k.text.split('\\xa0€/')\n",
    "                                resultados_dia['reference_price'].append(lst[0].lstrip(' (').replace(',', '.'))\n",
    "                                resultados_dia['reference_unit'].append(lst[1].rstrip(') ').lower())\n",
    "                        \n",
    "\n",
    "        # resetea nº botones\n",
    "        botones = []\n",
    "\n",
    "# cierra driver\n",
    "driver.quit()\n",
    "\n",
    "# to csv\n",
    "df = pd.DataFrame(resultados_dia)\n",
    "fecha = datetime.today().strftime('%Y-%m-%d %H-%M-%S')\n",
    "df.to_csv(f\"../scrapeo({fecha}).csv\", index=True, sep= \",\")\n",
    "\n",
    "# check total\n",
    "print(f'Productos scrapeados: {len(resultados_dia[\"name\"])} de {total}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
