{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejo de datos \n",
    "import pandas as pd # manejo de datos y dataframes\n",
    "import numpy as np # manejo de arrays y operaciones matematicas \n",
    "\n",
    "\n",
    "# Librerias para realizar web scraping con selenium\n",
    "from selenium import webdriver # webdriver permite manejar un navegador \n",
    "from webdriver_manager.chrome import ChromeDriverManager # permite instalar y mantener actualizado el driver de chrome\n",
    "from selenium.webdriver.common.keys import Keys # permite simular teclas del teclado \n",
    "from selenium.webdriver.chrome.options import Options # permite configurar el driver de chrome como modo incognito o maximizar la ventana\n",
    "from time import sleep # esperas entre ejecuciones de codigo\n",
    "\n",
    "\n",
    "import warnings # permite ignorar los warnings de python \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opciones= Options()\n",
    "opciones.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "\n",
    "# para ocultarme como robot\n",
    "opciones.add_experimental_option('useAutomationExtension', False)\n",
    "opciones.add_argument('--start-maximized') # empezar maximizado\n",
    "opciones.add_argument('user.data-dir=selenium') # guarda las cookies\n",
    "opciones.add_argument('--incognito') # incognito window"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "flag = 0\n",
    "flag2 = 0\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.dia.es/\") \n",
    "sleep(3)\n",
    "\n",
    "# aceptamos las cookies \n",
    "driver.find_element(\"css selector\", '#onetrust-accept-btn-handler').click()\n",
    "sleep(2)\n",
    "\n",
    "# clicka productos\n",
    "driver.find_element(\"css selector\", '#app > div > div > div > div.home-view__header > div.dia-header > div.dia-header__section.dia-header__section--start > div > div > button').click()\n",
    "sleep(2)\n",
    "\n",
    "# para cada una de las categorías principales\n",
    "# poner un max excesivo\n",
    "for category in range(1,31):\n",
    "\n",
    "    while 1:\n",
    "\n",
    "        # intenta clickar\n",
    "        try:\n",
    "            \n",
    "            driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[1]/div[1]/div[1]/div/div[2]/div/div/div[2]/ul/li[{category}]/a').click()\n",
    "            flag2 = 0\n",
    "\n",
    "            for subcategory in range (1,31):\n",
    "\n",
    "                while 1:\n",
    "\n",
    "                    try:\n",
    "                        \n",
    "                        urls.append(driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[1]/div[1]/div[1]/div/div[2]/div/div/div[2]/ul/li[{category}]/ul/div[{subcategory}]/a').get_attribute(\"href\"))\n",
    "                        sleep(0.1)\n",
    "                        break\n",
    "\n",
    "                    except:\n",
    "\n",
    "                        flag2 = 1\n",
    "                        break\n",
    "                    \n",
    "                if flag2:\n",
    "                    break\n",
    "            \n",
    "            sleep(1)\n",
    "            break\n",
    "        \n",
    "        # break si se acaban\n",
    "        except:\n",
    "\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag:\n",
    "\n",
    "        break\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(urls, columns=['url'])\n",
    "\n",
    "df.to_csv(\"../data/urls-dia.csv\", index=False, sep= \",\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sopa bonita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['url', 'supermarket', 'category', 'name', 'description', 'price', 'reference_price', 'reference_unit', 'insert_date', 'product_id']\n",
    "\n",
    "resultados_dia = {'url': 'https://www.dia.es/categoria/subcategoria/p/id',\n",
    "                \"supermarket\": 'dia-es',\n",
    "                \"category\":[],\n",
    "                'subcategory':[],\n",
    "                \"name\":[], \n",
    "                \"description\": [], \n",
    "                \"price\": [], \n",
    "                \"reference_price\": [],\n",
    "                \"reference_unit\": [],\n",
    "                \"insert_date\": datetime.today().strftime('%Y-%m-%d'),\n",
    "                \"product_id\": []}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# solo saca 10/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.dia.es/charcuteria-y-quesos/jamon-cocido-lacon-fiambres-y-mortadela/c/L2001'\n",
    "res = requests.get(url)\n",
    "sleep(1)\n",
    "\n",
    "print(res.status_code)\n",
    "\n",
    "sopa = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "#productos = sopa.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "productos = sopa.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "\n",
    "print(f'Cantidad de productos extraídos: {len(productos)}')\n",
    "\n",
    "print(productos[0])\n",
    "\n",
    "print(productos[0].text)\n",
    "\n",
    "productos\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scroll por pixel saca 20/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Get a page\n",
    "driver.get(\"https://www.dia.es/charcuteria-y-quesos/jamon-cocido-lacon-fiambres-y-mortadela/c/L2001\") \n",
    "sleep(2)\n",
    "\n",
    "Y = 1200\n",
    "driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "sleep(2)\n",
    "\n",
    "# Feed the source to BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "productos = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(f'Productos extraídos: {len(productos)} de 20')\n",
    "\n",
    "print(productos[-1].text)\n",
    "print(precio[-1].text)\n",
    "print(kilo[-1].text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crea una lista de listas, cada lista es una página de productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productos = []\n",
    "precio = []\n",
    "kilo = []\n",
    "\n",
    "# Create your driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Get a page\n",
    "driver.get(\"https://www.dia.es/charcuteria-y-quesos/jamon-cocido-lacon-fiambres-y-mortadela/c/L2001\")\n",
    "sleep(2)\n",
    "\n",
    "Y = 1200\n",
    "driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "sleep(2)\n",
    "\n",
    "# Feed the source to BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "productos = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(f'Productos extraídos: {len(productos)} de 20')\n",
    "\n",
    "print(productos)\n",
    "print(precio)\n",
    "print(kilo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bucle para meter todas las páginas de un producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productos = []\n",
    "precio = []\n",
    "kilo = []\n",
    "flag3 = 0\n",
    "\n",
    "# Create your driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "param = 'c'\n",
    "url = f'https://www.dia.es/charcuteria-y-quesos/jamon-cocido-lacon-fiambres-y-mortadela/{param}/L2001'\n",
    "\n",
    "# Get a page\n",
    "driver.get(url)\n",
    "sleep(2)\n",
    "\n",
    "Y = 1200\n",
    "driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "sleep(2)\n",
    "\n",
    "# Feed the source to BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "productos.append(soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"}))\n",
    "precio.append(soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"}))\n",
    "kilo.append(soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"}))\n",
    "\n",
    "for i in range(2,10):\n",
    "\n",
    "    param = f'pag-{i}'\n",
    "    url = f'https://www.dia.es/charcuteria-y-quesos/jamon-cocido-lacon-fiambres-y-mortadela/{param}/c/L2001'\n",
    "\n",
    "    driver.get(url)\n",
    "    sleep(2)\n",
    "\n",
    "    Y = 1200\n",
    "    driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "    sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    if soup.find_all(\"div\", {\"class\": \"plp-error-page__card\"}):\n",
    "\n",
    "        break\n",
    "\n",
    "    productos.append(soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"}))\n",
    "    precio.append(soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"}))\n",
    "    kilo.append(soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"}))\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(len(productos))\n",
    "print(precio)\n",
    "print(kilo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bucle para meter varias urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productos = []\n",
    "precio = []\n",
    "kilo = []\n",
    "flag3 = 0\n",
    "\n",
    "# creación del driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# c = página 1\n",
    "param = 'c'\n",
    "url = [f'https://www.dia.es/charcuteria-y-quesos/jamon-cocido-lacon-fiambres-y-mortadela/{param}/L2001', \n",
    "       f'https://www.dia.es/charcuteria-y-quesos/salchichas-y-elaborados/{param}/L2206']\n",
    "\n",
    "# get\n",
    "driver.get(u)\n",
    "sleep(2)\n",
    "\n",
    "# scroll down\n",
    "Y = 1200\n",
    "driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "sleep(2)\n",
    "\n",
    "# parseo html para sopa\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# apendea los resultados de la página 1\n",
    "productos.append(soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"}))\n",
    "precio.append(soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"}))\n",
    "kilo.append(soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"}))\n",
    "\n",
    "# itero i para modificar url\n",
    "for i in range(2,10):\n",
    "    \n",
    "    param = f'pag-{i}/c'\n",
    "\n",
    "    # para cada url de la lista:\n",
    "    for u in url:\n",
    "\n",
    "        driver.get(u)\n",
    "        sleep(2)\n",
    "\n",
    "        Y = 1200\n",
    "        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "        sleep(2)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        if soup.find_all(\"div\", {\"class\": \"plp-error-page__card\"}):\n",
    "\n",
    "            break\n",
    "\n",
    "        productos.append(soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"}))\n",
    "        precio.append(soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"}))\n",
    "        kilo.append(soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"}))\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(len(productos))\n",
    "print(precio)\n",
    "print(kilo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productos = []\n",
    "precio = []\n",
    "kilo = []\n",
    "\n",
    "# creación del driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "for i in range(2,11):\n",
    "\n",
    "    if i == 1:\n",
    "\n",
    "        param = 'c'\n",
    "\n",
    "    else:\n",
    "\n",
    "        param = f'pag-{i}/c'\n",
    "\n",
    "    url = [f'https://www.dia.es/charcuteria-y-quesos/jamon-cocido-lacon-fiambres-y-mortadela/{param}/L2001', f'https://www.dia.es/charcuteria-y-quesos/salchichas-y-elaborados/{param}/L2206']\n",
    "\n",
    "    for u in url:\n",
    "\n",
    "        # get\n",
    "        driver.get(u)\n",
    "        sleep(2)\n",
    "\n",
    "        # scroll down\n",
    "        Y = 1200\n",
    "        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "        sleep(2)\n",
    "\n",
    "        # parseo html para sopa\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # apendea los resultados de la página 1\n",
    "        productos.append(soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"}))\n",
    "        precio.append(soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"}))\n",
    "        kilo.append(soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoria = []\n",
    "subcategoria = []\n",
    "producto = []\n",
    "precio = []\n",
    "kilo = []\n",
    "id = []\n",
    "\n",
    "# creación del driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = ['https://www.dia.es/charcuteria-y-quesos/jamon-cocido-lacon-fiambres-y-mortadela/c/L2001', 'https://www.dia.es/charcuteria-y-quesos/salchichas-y-elaborados/c/L2206']\n",
    "\n",
    "for u in url:\n",
    "\n",
    "        # get\n",
    "        driver.get(u)\n",
    "        sleep(2)\n",
    "\n",
    "        # aceptamos las cookies\n",
    "        try:\n",
    "                driver.find_element(\"css selector\", '#onetrust-accept-btn-handler').click()\n",
    "                sleep(1)\n",
    "\n",
    "        except:\n",
    "                pass\n",
    "\n",
    "        # scroll down\n",
    "        Y = 1200\n",
    "        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "        sleep(2)\n",
    "\n",
    "        # parseo html para sopa\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # apendea los resultados de la página 1\n",
    "        id.append(soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"}))\n",
    "        categoria.append(soup.find(\"span\", {\"class\": \"plp-breadcrumb__first-level-category\"}))\n",
    "        subcategoria.append(soup.find(\"span\", {\"class\": \"plp-breadcrumb__second-level-category\"}))\n",
    "        producto.append(soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"}))\n",
    "        precio.append(soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"}))\n",
    "        kilo.append(soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"}))\n",
    "\n",
    "        if bool(soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})):\n",
    "                botones = soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})\n",
    "\n",
    "        else:\n",
    "                pass\n",
    "        \n",
    "        if botones:\n",
    "\n",
    "                for bottom in range(2, int(botones[-1].text)+1):\n",
    "                        \n",
    "                        driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div/div/div/div[{bottom}]/a').click()\n",
    "                        sleep(2)\n",
    "\n",
    "                        # scroll down\n",
    "                        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "                        sleep(2)\n",
    "\n",
    "                        # parseo html para sopa\n",
    "                        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                        # apendea los resultados de la página 1\n",
    "                        id.append(soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"}))\n",
    "                        categoria.append(soup.find(\"span\", {\"class\": \"plp-breadcrumb__first-level-category\"}))\n",
    "                        subcategoria.append(soup.find(\"span\", {\"class\": \"plp-breadcrumb__second-level-category\"}))\n",
    "                        producto.append(soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"}))\n",
    "                        precio.append(soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"}))\n",
    "                        kilo.append(soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"}))\n",
    "\n",
    "        botones = []\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(len(producto))\n",
    "print(categoria)\n",
    "print(subcategoria)\n",
    "print(producto)\n",
    "print(precio)\n",
    "print(kilo)\n",
    "print(id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['url', 'supermarket', 'category', 'name', 'description', 'price', 'reference_price', 'reference_unit', 'insert_date', 'product_id']\n",
    "\n",
    "resultados_dia = {'url': 'https://www.dia.es/categoria/subcategoria/p/id',\n",
    "                \"supermarket\": 'dia-es',\n",
    "                \"category\":[],\n",
    "                'subcategory':[],\n",
    "                \"name\":[], \n",
    "                \"description\": [], \n",
    "                \"price\": [], \n",
    "                \"reference_price\": [],\n",
    "                \"reference_unit\": [],\n",
    "                \"insert_date\": datetime.today().strftime('%Y-%m-%d'),\n",
    "                \"product_id\": []}\n",
    "\n",
    "resultados_dia;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creación del driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = ['https://www.dia.es/charcuteria-y-quesos/jamon-cocido-lacon-fiambres-y-mortadela/c/L2001', \n",
    "       'https://www.dia.es/charcuteria-y-quesos/salchichas-y-elaborados/c/L2206']\n",
    "\n",
    "for u in url:\n",
    "\n",
    "        # get\n",
    "        driver.get(u)\n",
    "        sleep(2)\n",
    "\n",
    "        # aceptamos las cookies\n",
    "        try:\n",
    "                driver.find_element(\"css selector\", '#onetrust-accept-btn-handler').click()\n",
    "                sleep(1)\n",
    "\n",
    "        except:\n",
    "                pass\n",
    "\n",
    "        # scroll down\n",
    "        Y = 1200\n",
    "        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "        sleep(2)\n",
    "\n",
    "        # parseo html para sopa\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # apendea los resultados de la página 1\n",
    "        cat = soup.find(\"span\", {\"class\": \"plp-breadcrumb__first-level-category\"})\n",
    "        sub = soup.find(\"span\", {\"class\": \"plp-breadcrumb__second-level-category\"})\n",
    "        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "        #id = soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "        \n",
    "        for p in prod:\n",
    "                resultados_dia['category'].append(cat.text)\n",
    "                resultados_dia['subcategory'].append(sub.text)\n",
    "                resultados_dia['name'].append(p.text)\n",
    "        \n",
    "        for o in precio:\n",
    "                resultados_dia['price'].append(o.text.rstrip('\\xa0€'))\n",
    "        \n",
    "        for k in kilo:\n",
    "                resultados_dia['reference_price'].append(k.text)\n",
    "        \n",
    "        #for i in id:\n",
    "                #resultados_dia['product_id'].append(i.text)\n",
    "        \n",
    "        # si hay botones, los encuentra\n",
    "        if bool(soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})):\n",
    "                botones = soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})\n",
    "\n",
    "        else:\n",
    "                pass\n",
    "        \n",
    "        # si hay botones (más páginas):\n",
    "        if botones:\n",
    "\n",
    "                # para cada botón siguiente (a partir del 2) hasta que se acaben:\n",
    "                for bottom in range(2, int(botones[-1].text)+1):\n",
    "                        \n",
    "                        driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div/div/div/div[{bottom}]/a').click()\n",
    "                        sleep(2)\n",
    "\n",
    "                        # scroll down\n",
    "                        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "                        sleep(2)\n",
    "\n",
    "                        # parseo html para sopa\n",
    "                        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                        # apendea los resultados de la página 1\n",
    "                        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "                        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "                        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "                        id = soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "                        \n",
    "                        for p in prod:\n",
    "                                resultados_dia['category'].append(cat.text)\n",
    "                                resultados_dia['subcategory'].append(sub.text)\n",
    "                                resultados_dia['name'].append(p.text)\n",
    "                        \n",
    "                        for o in precio:\n",
    "                                resultados_dia['price'].append(o.text.rstrip('\\xa0€'))\n",
    "                        \n",
    "                        for k in kilo:\n",
    "                                resultados_dia['reference_price'].append(k.text)\n",
    "                        \n",
    "                        #for i in id:\n",
    "                                #resultados_dia['product_id'].append(i.text)\n",
    "\n",
    "        botones = []\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "resultados_dia;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_dia = {'url': 'https://www.dia.es/categoria/subcategoria/p/id',\n",
    "                \"supermarket\": [],\n",
    "                \"category\":[],\n",
    "                'subcategory':[],\n",
    "                \"name\":[], \n",
    "                \"description\": [], \n",
    "                \"price\": [], \n",
    "                \"reference_price\": [],\n",
    "                \"reference_unit\": [],\n",
    "                \"insert_date\": [],\n",
    "                \"product_id\": []}\n",
    "\n",
    "# creación del driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = ['https://www.dia.es/charcuteria-y-quesos/jamon-cocido-lacon-fiambres-y-mortadela/c/L2001', \n",
    "       'https://www.dia.es/charcuteria-y-quesos/salchichas-y-elaborados/c/L2206']\n",
    "\n",
    "for u in url:\n",
    "\n",
    "        # get\n",
    "        driver.get(u)\n",
    "        sleep(2)\n",
    "\n",
    "        # aceptamos las cookies\n",
    "        try:\n",
    "                driver.find_element(\"css selector\", '#onetrust-accept-btn-handler').click()\n",
    "                sleep(1)\n",
    "\n",
    "        except:\n",
    "                pass\n",
    "\n",
    "        # scroll down\n",
    "        Y = 1200\n",
    "        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "        sleep(2)\n",
    "\n",
    "        # parseo html para sopa\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # apendea los resultados de la página 1\n",
    "        cat = soup.find(\"span\", {\"class\": \"plp-breadcrumb__first-level-category\"})\n",
    "        sub = soup.find(\"span\", {\"class\": \"plp-breadcrumb__second-level-category\"})\n",
    "        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "        #id = soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "        \n",
    "        for p in prod:\n",
    "                resultados_dia['supermarket'].append('dia-es')\n",
    "                resultados_dia['category'].append(cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                resultados_dia['subcategory'].append(sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                resultados_dia['name'].append(p.text)\n",
    "                resultados_dia['insert_date'].append(datetime.today().strftime('%Y-%m-%d'))\n",
    "        \n",
    "        for o in precio:\n",
    "                resultados_dia['price'].append(o.text.rstrip('\\xa0€'))\n",
    "        \n",
    "        for k in kilo:\n",
    "                lst = k.text.split('\\xa0€/')\n",
    "                resultados_dia['reference_price'].append(lst[0].lstrip(' ('))\n",
    "                resultados_dia['reference_unit'].append(lst[1].rstrip(') ').lower())\n",
    "        \n",
    "        #for i in id:\n",
    "                #resultados_dia['product_id'].append(i.text)\n",
    "        \n",
    "        # si hay botones, los encuentra\n",
    "        if bool(soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})):\n",
    "                botones = soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})\n",
    "\n",
    "        else:\n",
    "                pass\n",
    "        \n",
    "        # si hay botones (más páginas):\n",
    "        if botones:\n",
    "\n",
    "                # para cada botón siguiente (a partir del 2) hasta que se acaben:\n",
    "                for bottom in range(2, int(botones[-1].text)+1):\n",
    "                        \n",
    "                        driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div/div/div/div[{bottom}]/a').click()\n",
    "                        sleep(2)\n",
    "\n",
    "                        # scroll down\n",
    "                        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "                        sleep(2)\n",
    "\n",
    "                        # parseo html para sopa\n",
    "                        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                        # apendea los resultados de la página 1\n",
    "                        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "                        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "                        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "                        id = soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "                        \n",
    "                        for p in prod:\n",
    "                                resultados_dia['supermarket'].append('dia-es')\n",
    "                                resultados_dia['category'].append(cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                                resultados_dia['subcategory'].append(sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                                resultados_dia['name'].append(p.text)\n",
    "                                resultados_dia['insert_date'].append(datetime.today().strftime('%Y-%m-%d'))\n",
    "                        \n",
    "                        for o in precio:\n",
    "                                resultados_dia['price'].append(o.text.rstrip('\\xa0€'))\n",
    "                        \n",
    "                        for k in kilo:\n",
    "                                lst = k.text.split('\\xa0€/')\n",
    "                                resultados_dia['reference_price'].append(lst[0].lstrip(' ('))\n",
    "                                resultados_dia['reference_unit'].append(lst[1].rstrip(') ').lower())\n",
    "                        \n",
    "                        #for i in id:\n",
    "                                #resultados_dia['product_id'].append(i.text)\n",
    "\n",
    "        botones = []\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "resultados_dia;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_dia = {'url': 'https://www.dia.es/categoria/subcategoria/p/id',\n",
    "                \"supermarket\": [],\n",
    "                \"category\":[],\n",
    "                'subcategory':[],\n",
    "                \"name\":[], \n",
    "                \"description\": [], \n",
    "                \"price\": [], \n",
    "                \"reference_price\": [],\n",
    "                \"reference_unit\": [],\n",
    "                \"insert_date\": [],\n",
    "                \"product_id\": []}\n",
    "\n",
    "resultados_dia = {\"supermarket\": [],\n",
    "                \"category\":[],\n",
    "                'subcategory':[],\n",
    "                \"name\":[], \n",
    "                \"price\": [], \n",
    "                \"reference_price\": [],\n",
    "                \"reference_unit\": [],\n",
    "                \"insert_date\": []}\n",
    "\n",
    "# creación del driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "for u in urls:\n",
    "\n",
    "        # get\n",
    "        driver.get(u)\n",
    "        sleep(2)\n",
    "\n",
    "        # aceptamos las cookies\n",
    "        try:\n",
    "                driver.find_element(\"css selector\", '#onetrust-accept-btn-handler').click()\n",
    "                sleep(1)\n",
    "\n",
    "        except:\n",
    "                pass\n",
    "\n",
    "        # scroll down\n",
    "        Y = 1200\n",
    "        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "        sleep(2)\n",
    "\n",
    "        # parseo html para sopa\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # apendea los resultados de la página 1\n",
    "        cat = soup.find(\"span\", {\"class\": \"plp-breadcrumb__first-level-category\"})\n",
    "        sub = soup.find(\"span\", {\"class\": \"plp-breadcrumb__second-level-category\"})\n",
    "        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "        #id = soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "        \n",
    "        for p in prod:\n",
    "                resultados_dia['supermarket'].append('dia-es')\n",
    "                resultados_dia['category'].append(cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                resultados_dia['subcategory'].append(sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                resultados_dia['name'].append(p.text)\n",
    "                resultados_dia['insert_date'].append(datetime.today().strftime('%Y-%m-%d'))\n",
    "        \n",
    "        for o in precio:\n",
    "                resultados_dia['price'].append(o.text.rstrip('\\xa0€'))\n",
    "        \n",
    "        for k in kilo:\n",
    "                lst = k.text.split('\\xa0€/')\n",
    "                resultados_dia['reference_price'].append(lst[0].lstrip(' ('))\n",
    "                resultados_dia['reference_unit'].append(lst[1].rstrip(') ').lower())\n",
    "        \n",
    "        #for i in id:\n",
    "                #resultados_dia['product_id'].append(i.text)\n",
    "        \n",
    "        # si hay botones, los encuentra\n",
    "        if bool(soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})):\n",
    "                botones = soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})\n",
    "\n",
    "        else:\n",
    "                pass\n",
    "        \n",
    "        # si hay botones (más páginas):\n",
    "        if botones:\n",
    "\n",
    "                # para cada botón siguiente (a partir del 2) hasta que se acaben:\n",
    "                for bottom in range(2, int(botones[-1].text)+1):\n",
    "                        \n",
    "                        try:\n",
    "                                driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div/div/div/div[{bottom}]/a').click()\n",
    "                                sleep(2)\n",
    "                        \n",
    "                        except:\n",
    "                                driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div[1]/div/div/div[{bottom}]/a').click()\n",
    "                                \n",
    "                        \n",
    "                        # scroll down\n",
    "                        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "                        sleep(2)\n",
    "\n",
    "                        # parseo html para sopa\n",
    "                        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                        # apendea los resultados de la página 1\n",
    "                        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "                        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "                        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "                        id = soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "                        \n",
    "                        for p in prod:\n",
    "                                resultados_dia['supermarket'].append('dia-es')\n",
    "                                resultados_dia['category'].append(cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                                resultados_dia['subcategory'].append(sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                                resultados_dia['name'].append(p.text)\n",
    "                                resultados_dia['insert_date'].append(datetime.today().strftime('%Y-%m-%d'))\n",
    "                        \n",
    "                        for o in precio:\n",
    "                                resultados_dia['price'].append(o.text.rstrip('\\xa0€'))\n",
    "                        \n",
    "                        for k in kilo:\n",
    "                                lst = k.text.split('\\xa0€/')\n",
    "                                resultados_dia['reference_price'].append(lst[0].lstrip(' ('))\n",
    "                                resultados_dia['reference_unit'].append(lst[1].rstrip(') ').lower())\n",
    "                        \n",
    "                        #for i in id:\n",
    "                                #resultados_dia['product_id'].append(i.text)\n",
    "\n",
    "        botones = []\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "resultados_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(resultados_dia)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_dia = {\"supermarket\": [],\n",
    "                \"category\":[],\n",
    "                'subcategory':[],\n",
    "                \"name\":[], \n",
    "                \"price\": [], \n",
    "                \"reference_price\": [],\n",
    "                \"reference_unit\": [],\n",
    "                \"insert_date\": []}\n",
    "\n",
    "# creación del driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = ['https://www.dia.es/charcuteria-y-quesos/salchichas-y-elaborados/c/L2206',\n",
    "       'https://www.dia.es/conservas-caldos-y-cremas/conservas-vegetales/c/L2092']\n",
    "\n",
    "for u in url:\n",
    "\n",
    "        # get\n",
    "        driver.get(u)\n",
    "        sleep(2)\n",
    "\n",
    "        # aceptamos las cookies\n",
    "        try:\n",
    "                driver.find_element(\"css selector\", '#onetrust-accept-btn-handler').click()\n",
    "                sleep(1)\n",
    "\n",
    "        except:\n",
    "                pass\n",
    "\n",
    "        # scroll down\n",
    "        Y = 1200\n",
    "        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "        sleep(2)\n",
    "\n",
    "        # parseo html para sopa\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # apendea los resultados de la página 1\n",
    "        cat = soup.find(\"span\", {\"class\": \"plp-breadcrumb__first-level-category\"})\n",
    "        sub = soup.find(\"span\", {\"class\": \"plp-breadcrumb__second-level-category\"})\n",
    "        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "        #id = soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "        \n",
    "        for p in prod:\n",
    "                resultados_dia['supermarket'].append('dia-es')\n",
    "                resultados_dia['category'].append(cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                resultados_dia['subcategory'].append(sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                resultados_dia['name'].append(p.text)\n",
    "                resultados_dia['insert_date'].append(datetime.today().strftime('%Y-%m-%d'))\n",
    "        \n",
    "        for o in precio:\n",
    "                resultados_dia['price'].append(o.text.rstrip('\\xa0€'))\n",
    "        \n",
    "        for k in kilo:\n",
    "                lst = k.text.split('\\xa0€/')\n",
    "                resultados_dia['reference_price'].append(lst[0].lstrip(' ('))\n",
    "                resultados_dia['reference_unit'].append(lst[1].rstrip(') ').lower())\n",
    "        \n",
    "        #for i in id:\n",
    "                #resultados_dia['product_id'].append(i.text)\n",
    "        \n",
    "        # si hay botones, los encuentra\n",
    "        if bool(soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})):\n",
    "                botones = soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})\n",
    "\n",
    "        else:\n",
    "                pass\n",
    "        \n",
    "        # si hay botones (más páginas):\n",
    "        if botones:\n",
    "\n",
    "                # para cada botón siguiente (a partir del 2) hasta que se acaben:\n",
    "                for bottom in range(2, int(botones[-1].text)+1):\n",
    "\n",
    "                        try:\n",
    "                                driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div/div/div/div[{bottom}]/a').click()\n",
    "                                sleep(2)\n",
    "                        \n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "                \n",
    "                        # scroll down\n",
    "                        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "                        sleep(2)\n",
    "\n",
    "                        # parseo html para sopa\n",
    "                        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                        # apendea los resultados de la página 1\n",
    "                        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "                        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "                        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "                        id = soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "                        \n",
    "                        for p in prod:\n",
    "                                resultados_dia['supermarket'].append('dia-es')\n",
    "                                resultados_dia['category'].append(cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                                resultados_dia['subcategory'].append(sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                                resultados_dia['name'].append(p.text)\n",
    "                                resultados_dia['insert_date'].append(datetime.today().strftime('%Y-%m-%d'))\n",
    "                        \n",
    "                        for o in precio:\n",
    "                                resultados_dia['price'].append(o.text.rstrip('\\xa0€'))\n",
    "                        \n",
    "                        for k in kilo:\n",
    "                                lst = k.text.split('\\xa0€/')\n",
    "                                resultados_dia['reference_price'].append(lst[0].lstrip(' ('))\n",
    "                                resultados_dia['reference_unit'].append(lst[1].rstrip(') ').lower())\n",
    "                        \n",
    "                        #for i in id:\n",
    "                                #resultados_dia['product_id'].append(i.text)\n",
    "\n",
    "        botones = []\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "resultados_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_dia = {\"supermarket\": [],\n",
    "                \"category\":[],\n",
    "                'subcategory':[],\n",
    "                \"name\":[], \n",
    "                \"price\": [], \n",
    "                \"reference_price\": [],\n",
    "                \"reference_unit\": [],\n",
    "                \"insert_date\": []}\n",
    "\n",
    "# creación del driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = ['https://www.dia.es/charcuteria-y-quesos/salchichas-y-elaborados/c/L2206',\n",
    "       'https://www.dia.es/conservas-caldos-y-cremas/conservas-vegetales/c/L2092']\n",
    "\n",
    "for u in url:\n",
    "\n",
    "        # get\n",
    "        driver.get(u)\n",
    "        sleep(2)\n",
    "\n",
    "        # aceptamos las cookies\n",
    "        try:\n",
    "                driver.find_element(\"css selector\", '#onetrust-accept-btn-handler').click()\n",
    "                sleep(1)\n",
    "\n",
    "        except:\n",
    "                pass\n",
    "\n",
    "        # scroll down\n",
    "        Y = 1200\n",
    "        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "        sleep(2)\n",
    "\n",
    "        # parseo html para sopa\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # apendea los resultados de la página 1\n",
    "        cat = soup.find(\"span\", {\"class\": \"plp-breadcrumb__first-level-category\"})\n",
    "        sub = soup.find(\"span\", {\"class\": \"plp-breadcrumb__second-level-category\"})\n",
    "        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "        #id = soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "        \n",
    "        for p in prod:\n",
    "                resultados_dia['supermarket'].append('dia-es')\n",
    "                resultados_dia['category'].append(cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                resultados_dia['subcategory'].append(sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                resultados_dia['name'].append(p.text)\n",
    "                resultados_dia['insert_date'].append(datetime.today().strftime('%Y-%m-%d'))\n",
    "        \n",
    "        for o in precio:\n",
    "                resultados_dia['price'].append(o.text.rstrip('\\xa0€'))\n",
    "        \n",
    "        for k in kilo:\n",
    "                lst = k.text.split('\\xa0€/')\n",
    "                resultados_dia['reference_price'].append(lst[0].lstrip(' ('))\n",
    "                resultados_dia['reference_unit'].append(lst[1].rstrip(') ').lower())\n",
    "        \n",
    "        #for i in id:\n",
    "                #resultados_dia['product_id'].append(i.text)\n",
    "        \n",
    "        # si hay botones, los encuentra\n",
    "        if bool(soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})):\n",
    "                botones = soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})\n",
    "\n",
    "        else:\n",
    "                pass\n",
    "        \n",
    "        # si hay botones (más páginas):\n",
    "        if botones:\n",
    "\n",
    "                # para cada botón siguiente (a partir del 2) hasta que se acaben:\n",
    "                for bottom in range(2, int(botones[-1].text)+1):\n",
    "\n",
    "                        try:\n",
    "                                driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div/div/div/div[{bottom}]/a').click()\n",
    "                                sleep(2)\n",
    "                        \n",
    "                        except:\n",
    "                                try:\n",
    "                                        driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div[1]/a[2]').click()\n",
    "                                        sleep(2)\n",
    "                                except:\n",
    "                                        pass\n",
    "\n",
    "                                pass\n",
    "                        \n",
    "\n",
    "                \n",
    "                        # scroll down\n",
    "                        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "                        sleep(2)\n",
    "\n",
    "                        # parseo html para sopa\n",
    "                        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                        # apendea los resultados de la página 1\n",
    "                        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "                        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "                        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "                        id = soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "                        \n",
    "                        for p in prod:\n",
    "                                resultados_dia['supermarket'].append('dia-es')\n",
    "                                resultados_dia['category'].append(cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                                resultados_dia['subcategory'].append(sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                                resultados_dia['name'].append(p.text)\n",
    "                                resultados_dia['insert_date'].append(datetime.today().strftime('%Y-%m-%d'))\n",
    "                        \n",
    "                        for o in precio:\n",
    "                                resultados_dia['price'].append(o.text.rstrip('\\xa0€'))\n",
    "                        \n",
    "                        for k in kilo:\n",
    "                                lst = k.text.split('\\xa0€/')\n",
    "                                resultados_dia['reference_price'].append(lst[0].lstrip(' ('))\n",
    "                                resultados_dia['reference_unit'].append(lst[1].rstrip(') ').lower())\n",
    "                        \n",
    "                        #for i in id:\n",
    "                                #resultados_dia['product_id'].append(i.text)\n",
    "\n",
    "        botones = []\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "resultados_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictio con los resultados del scrapeo\n",
    "resultados_dia = {\"supermarket\": [],\n",
    "                \"category\":[],\n",
    "                'subcategory':[],\n",
    "                \"name\":[], \n",
    "                \"price\": [], \n",
    "                \"reference_price\": [],\n",
    "                \"reference_unit\": [],\n",
    "                \"insert_date\": []}\n",
    "\n",
    "# creación del driver de chrome\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# para cada uno de los urls que han salido del primer Selenium\n",
    "for u in urls:\n",
    "\n",
    "        # get\n",
    "        driver.get(u)\n",
    "        sleep(2)\n",
    "\n",
    "        # acepta las cookies\n",
    "        try:\n",
    "                driver.find_element(\"css selector\", '#onetrust-accept-btn-handler').click()\n",
    "                sleep(1)\n",
    "\n",
    "        except:\n",
    "                pass\n",
    "\n",
    "        # scroll down\n",
    "        Y = 1200\n",
    "        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "        sleep(2)\n",
    "\n",
    "        # parsea html para sopa\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # listas resultados primera página\n",
    "        cat = soup.find(\"span\", {\"class\": \"plp-breadcrumb__first-level-category\"})\n",
    "        sub = soup.find(\"span\", {\"class\": \"plp-breadcrumb__second-level-category\"})\n",
    "        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "        #id = soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "        \n",
    "        # apendea los resultados de las listas al dictio extrayendo texto de labels y retocando con métodos de strings\n",
    "        for p in prod:\n",
    "                resultados_dia['supermarket'].append('dia-es')\n",
    "                resultados_dia['category'].append(cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                resultados_dia['subcategory'].append(sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                resultados_dia['name'].append(p.text)\n",
    "                resultados_dia['insert_date'].append(datetime.today().strftime('%Y-%m-%d'))\n",
    "        \n",
    "        for o in precio:\n",
    "                resultados_dia['price'].append(o.text.rstrip('\\xa0€'))\n",
    "        \n",
    "        for k in kilo:\n",
    "                lst = k.text.split('\\xa0€/')\n",
    "                resultados_dia['reference_price'].append(lst[0].lstrip(' ('))\n",
    "                resultados_dia['reference_unit'].append(lst[1].rstrip(') ').lower())\n",
    "        \n",
    "        #for i in id:\n",
    "                #resultados_dia['product_id'].append(i.text)\n",
    "        \n",
    "        # si hay botones, los encuentra\n",
    "        if bool(soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})):\n",
    "                botones = soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})\n",
    "\n",
    "        else:\n",
    "                pass\n",
    "        \n",
    "        # si hay botones (más páginas):\n",
    "        if botones:\n",
    "\n",
    "                # para cada botón siguiente (a partir del 2) hasta que se acaben:\n",
    "                for bottom in range(2, int(botones[-1].text)+1):\n",
    "\n",
    "                        # intenta clickar el botón\n",
    "                        try:\n",
    "                                driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div/div/div/div[{bottom}]/a').click()\n",
    "                                sleep(2)\n",
    "                        \n",
    "                        except:\n",
    "                                # para cuando hay botones flecha (+5 páginas)\n",
    "                                try:\n",
    "                                        driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div[1]/a[2]').click()\n",
    "                                        sleep(2)\n",
    "                                except:\n",
    "                                        pass\n",
    "\n",
    "                                pass\n",
    "                        \n",
    "                        # SE REPITE EL PROCESO ANTERIOR PARA EL RESTO DE PÁGINAS:\n",
    "                        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "                        sleep(2)\n",
    "\n",
    "                        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "                        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "                        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "                        id = soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "                        \n",
    "                        for p in prod:\n",
    "                                resultados_dia['supermarket'].append('dia-es')\n",
    "                                resultados_dia['category'].append(cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                                resultados_dia['subcategory'].append(sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                                resultados_dia['name'].append(p.text)\n",
    "                                resultados_dia['insert_date'].append(datetime.today().strftime('%Y-%m-%d'))\n",
    "                        \n",
    "                        for o in precio:\n",
    "                                resultados_dia['price'].append(o.text.rstrip('\\xa0€'))\n",
    "                        \n",
    "                        for k in kilo:\n",
    "                                lst = k.text.split('\\xa0€/')\n",
    "                                resultados_dia['reference_price'].append(lst[0].lstrip(' ('))\n",
    "                                resultados_dia['reference_unit'].append(lst[1].rstrip(') ').lower())\n",
    "                        \n",
    "                        #for i in id:\n",
    "                                #resultados_dia['product_id'].append(i.text)\n",
    "\n",
    "        # resetea nº botones\n",
    "        botones = []\n",
    "\n",
    "# cierra driver\n",
    "driver.quit()\n",
    "\n",
    "# show\n",
    "resultados_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(resultados_dia)\n",
    "\n",
    "df2.to_csv(\"../scrapeo.csv\", index=False, sep= \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictio con los resultados del scrapeo\n",
    "resultados_dia = {\"supermarket\": [],\n",
    "                \"category\":[],\n",
    "                'subcategory':[],\n",
    "                \"name\":[], \n",
    "                \"price\": [], \n",
    "                \"reference_price\": [],\n",
    "                \"reference_unit\": [],\n",
    "                \"insert_date\": []}\n",
    "\n",
    "# creación del driver de chrome\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# para cada uno de los urls que han salido del primer Selenium\n",
    "for u in urls:\n",
    "\n",
    "        # get\n",
    "        driver.get(u)\n",
    "        sleep(2)\n",
    "\n",
    "        # acepta las cookies\n",
    "        try:\n",
    "                driver.find_element(\"css selector\", '#onetrust-accept-btn-handler').click()\n",
    "                sleep(1)\n",
    "\n",
    "        except:\n",
    "                pass\n",
    "\n",
    "        # scroll down\n",
    "        Y = 1200\n",
    "        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "        sleep(2)\n",
    "\n",
    "        # parsea html para sopa\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # listas resultados primera página\n",
    "        cat = soup.find(\"span\", {\"class\": \"plp-breadcrumb__first-level-category\"})\n",
    "        sub = soup.find(\"span\", {\"class\": \"plp-breadcrumb__second-level-category\"})\n",
    "        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "        #id = soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "        \n",
    "        # apendea los resultados de las listas al dictio extrayendo texto de labels y retocando con métodos de strings\n",
    "        for p in prod:\n",
    "                resultados_dia['supermarket'].append('dia-es')\n",
    "                resultados_dia['category'].append(cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                resultados_dia['subcategory'].append(sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                resultados_dia['name'].append(p.text)\n",
    "                resultados_dia['insert_date'].append(datetime.today().strftime('%Y-%m-%d'))\n",
    "        \n",
    "        for o in precio:\n",
    "                resultados_dia['price'].append(o.text.rstrip('\\xa0€'))\n",
    "        \n",
    "        for k in kilo:\n",
    "                lst = k.text.split('\\xa0€/')\n",
    "                resultados_dia['reference_price'].append(lst[0].lstrip(' ('))\n",
    "                resultados_dia['reference_unit'].append(lst[1].rstrip(') ').lower())\n",
    "        \n",
    "        #for i in id:\n",
    "                #resultados_dia['product_id'].append(i.text)\n",
    "        \n",
    "        # si hay botones, los encuentra\n",
    "        if bool(soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})):\n",
    "                botones = soup.find_all(\"a\", {\"class\": \"pagination-button__page--links\"})\n",
    "\n",
    "        else:\n",
    "                pass\n",
    "        \n",
    "        # si hay botones (más páginas):\n",
    "        if botones:\n",
    "\n",
    "                # para cada botón siguiente (a partir del 2) hasta que se acaben:\n",
    "                for bottom in range(2, int(botones[-1].text)+1):\n",
    "\n",
    "                        # intenta clickar el botón\n",
    "                        try:\n",
    "                                driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div/div/div/div[{bottom}]/a').click()\n",
    "                                sleep(2)\n",
    "                        \n",
    "                        except:\n",
    "                                # para cuando hay botones flecha (+5 páginas)\n",
    "                                try:\n",
    "                                        driver.find_element(\"xpath\", f'//*[@id=\"app\"]/div/div/div/div[2]/div[2]/div[3]/div[2]/div[1]/a[2]').click()\n",
    "                                        sleep(2)\n",
    "                                except:\n",
    "                                        pass\n",
    "\n",
    "                                pass\n",
    "                        \n",
    "                        # SE REPITE EL PROCESO ANTERIOR PARA EL RESTO DE PÁGINAS:\n",
    "                        driver.execute_script(f\"window.scrollTo(0, {Y})\") \n",
    "                        sleep(2)\n",
    "\n",
    "                        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                        prod = soup.find_all(\"p\", {\"class\": \"search-product-card__product-name\"})\n",
    "                        precio = soup.find_all(\"p\", {\"class\": \"search-product-card__active-price\"})\n",
    "                        kilo = soup.find_all(\"p\", {\"class\": \"search-product-card__price-per-unit\"})\n",
    "                        id = soup.find_all(\"div\", {\"class\": \"search-product-card search-product-card__dia-border product-card-list__item\"})\n",
    "                        \n",
    "                        for p in prod:\n",
    "                                resultados_dia['supermarket'].append('dia-es')\n",
    "                                resultados_dia['category'].append(cat.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                                resultados_dia['subcategory'].append(sub.text.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace(',', '').replace(\" \", \"_\"))\n",
    "                                resultados_dia['name'].append(p.text)\n",
    "                                resultados_dia['insert_date'].append(datetime.today().strftime('%Y-%m-%d'))\n",
    "                        \n",
    "                        for o in precio:\n",
    "                                resultados_dia['price'].append(o.text.rstrip('\\xa0€').replace(',', '.'))\n",
    "                        \n",
    "                        for k in kilo:\n",
    "                                lst = k.text.split('\\xa0€/')\n",
    "                                resultados_dia['reference_price'].append(lst[0].lstrip(' (')).replace(',', '.')\n",
    "                                resultados_dia['reference_unit'].append(lst[1].rstrip(') ').lower())\n",
    "                        \n",
    "                        #for i in id:\n",
    "                                #resultados_dia['product_id'].append(i.text)\n",
    "\n",
    "        # resetea nº botones\n",
    "        botones = []\n",
    "\n",
    "# cierra driver\n",
    "driver.quit()\n",
    "\n",
    "# show\n",
    "resultados_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
